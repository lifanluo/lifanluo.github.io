<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Lifan Luo</title>

    <meta name="author" content="Lifan Luo">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Lifan Luo
                </p>
                <p>
		            <p>
                I am a final-year PhD candidate at the 
                <a href="https://hkust.edu.hk/" target="_blank">Hong Kong University of Science and Technology (HKUST)</a>, 
                advised by 
                <a href="https://www.polyu.edu.hk/me/people/academic-teaching-staff/" target="_blank">Prof. Hongyu Yu</a> 
                and 
                <a href="https://seng.hkust.edu.hk/about/people/faculty/zhenyu-gao" target="_blank">Prof. Zhenyu Gao</a>. 
                I am currently a visiting research student at King’s College London (KCL), 
                advised by 
                <a href="https://shanluo.github.io/" target="_blank">Prof. Shan Luo</a>.
                </p>
                <p>
                  I'm interested in developing miniaturized vision-based tactile and multimodal sensors to enhance robotic manipulation.
                </p>
                <p style="text-align:center">
                  <a href="mailto:lluoan@connect.ust.hk">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=ryLAh2sAAAAJ&hl=en">Scholar</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/lifan.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 0%;" alt="profile photo" src="images/lifan.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                <p>
                  * indicates equal contribution
                </p>
                <!-- Paper 1 -->
                <table style="width:100%;border:0px;border-spacing:0px 10px;margin-bottom:10px;">
                  <tr>
                    <td style="padding:0px;width:25%;vertical-align:middle;">
                      <img src="images/flipping.jpg" alt="LTDOM" style="width:100%;border-radius:6px;">
                    </td>
                    <td style="padding-left:15px;vertical-align:middle;">
                      <p>
                        Chao Zhao*, Chunli Jiang*, <strong>Lifan Luo*</strong>, Shuai Yuan, Qifeng Chen, Hongyu Yu.<br>
                        <em>Learning Thin Deformable Object Manipulation with a Multi-Sensory Integrated Soft Hand.</em><br>
                        <i>IEEE Transactions on Robotics</i>, 2025.<br>
                        [<a href="https://robotll.github.io/LTDOM/">Website</a>]
                        [<a href="https://arxiv.org/pdf/2411.13952">ArXiv</a>]
                        [<a href="https://ieeexplore.ieee.org/document/11077998" target="_blank">DOI</a>]
                      </p>
                    </td>
                  </tr>
                </table>

                <!-- Paper 2 -->
                <table style="width:100%;border:0px;border-spacing:0px 10px;margin-bottom:10px;">
                  <tr>
                    <td style="padding:0px;width:25%;vertical-align:middle;">
                      <img src="images/compdvision.jpg" alt="CompdVision" style="width:100%;border-radius:6px;">
                    </td>
                    <td style="padding-left:15px;vertical-align:middle;">
                      <p>
                        <strong>Lifan Luo</strong>, Boyang Zhang, Zhijie Peng, Yik Kin Cheung, Guanlan Zhang, Zhigang Li, Michael Yu Wang, Hongyu Yu.<br>
                        <em>CompdVision: Combining Near-Field 3D Visual and Tactile Sensing Using a Compact Compound-Eye Imaging System.</em><br>
                        <i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i>, 2024, pp. 262–268.<br>
                        [<a href="https://hkust-orisys.github.io/CompdVision">Website</a>]
                        [<a href="https://arxiv.org/pdf/2312.07146">ArXiv</a>]
                        [<a href="https://doi.org/10.1109/IROS58592.2024.10801461" target="_blank">DOI</a>]
                      </p>
                    </td>
                  </tr>
                </table>

                <!-- Paper 3 -->
                <table style="width:100%;border:0px;border-spacing:0px 10px;margin-bottom:10px;">
                  <tr>
                    <td style="padding:0px;width:25%;vertical-align:middle;">
                      <img src="images/gripper.jpg" alt="Soft Robotics" style="width:100%;border-radius:6px;">
                    </td>
                    <td style="padding-left:15px;vertical-align:middle;">
                      <p>
                        Dickson Chiu Yu Wong, Mingtan Li, Shijie Kang, <strong>Lifan Luo</strong>, Hongyu Yu.<br>
                        <em>Reconfigurable, Transformable Soft Pneumatic Actuator with Tunable Three-Dimensional Deformations for Dexterous Soft Robotics Applications.</em><br>
                        <i>Soft Robotics</i>, vol. 12, no. 2, pp. 228–241, 2025.<br>
                        [<a href="https://arxiv.org/abs/2311.03032">ArXiv</a>]
                        [<a href="https://www.liebertpub.com/doi/abs/10.1089/soro.2023.0072" target="_blank">DOI</a>]
                      </p>
                    </td>
                  </tr>
                </table>

                <!-- Paper 4 -->
                <table style="width:100%;border:0px;border-spacing:0px 10px;margin-bottom:10px;">
                  <tr>
                    <td style="padding:0px;width:25%;vertical-align:middle;">
                      <img src="images/mrchaos.jpg" alt="ICRA 2025" style="width:100%;border-radius:6px;">
                    </td>
                    <td style="padding-left:15px;vertical-align:middle;">
                      <p>
                        Chao Zhao, Chunli Jiang, <strong>Lifan Luo</strong>, Guanlan Zhang, Hongyu Yu, Michael Yu Wang, Qifeng Chen.<br>
                        <em>Master Rules from Chaos: Learning to Reason, Plan, and Interact from Chaos for Tangram Assembly.</em><br>
                        <i>IEEE International Conference on Robotics and Automation (ICRA)</i>, 2025, pp. 11503–11509.<br>
                        [<a href="https://arxiv.org/pdf/2505.11818">ArXiv</a>]
                        [<a href="https://doi.org/10.1109/ICRA55743.2025.11127610" target="_blank">DOI</a>]
                      </p>
                    </td>
                  </tr>
                </table>                
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        </td>
      </tr>
    </table>
  </body>
</html>
